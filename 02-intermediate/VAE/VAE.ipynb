{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE (Variational Auto Encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. 모델 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 목표: Generative Model\n",
    "* 데이터 X의 잠재변수 z(Latent Vector)를 도출하고 \n",
    "* z의 random sample 을 통해 데이터 X의 분포를 추정함으로써 분포로부터 유사한 결과를 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"../../shared/VAE_intuition.png\" alt=\"Drawing\" style=\"width: 500px;\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구성: Encoder + Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Encoder**: Recognition Model 의 역할을 한다고 해석할 수 있음\n",
    "* **Decoder**: Generative Model 의 역할을 한다고 해석할 수 있고, \"실제 VAE의 목표\"가 되는 부분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../shared/VAE_step.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 과정:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) **Variational Inference** - 데이터 X로부터의 잠재변수 z를 decode했을 때 \"실제와 유사한\" 데이터를 잘 생성하는 z의 분포($p(z|x)$) 를 찾는 목표의 대안으로.. \n",
    "* $ p(z|x) = {{p(x|z)p(z)}\\over{p(x)}}$ 를 찾기 위해 실제 \"모든\" 데이터 X의 분포 $ P(x) $를 알아야하는데 이는 train 데이터만으로 알 수 없음 ($ \\; p(x) = \\int{p(x|z)p(z)dz} \\;$ 계산 불가능)\n",
    "* 따라서 어떤 \"계산 가능한\" 확률분포 $ q(z|x) $를 두어 $ q(z|x) $ 가 $ p(z|x) $에 근사하도록 학습 (Variational Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) **argmax$ELBO(\\phi)$** - $ q(z|x)$의 모수(parameter) $ \\phi $를 조정하여 min$KL(q(z|x)||p(z|x))$ 가 되게 하는 모수를 찾는 목표의 대안으로..\n",
    "* $p(x)$를 알기 위해 $log(p(x))$를 계산해보면 $log(p(x)) = ELBO(\\phi) + KL(q(z|x)||p(z|x))$ 형태로 표현됨\n",
    "* KL-divergence 를 최소화하는 $q(z|x)$의 모수 $\\phi$ 를 찾으면 되는데 $(p(z|x))$를 모르기 때문에 KL-term을 최소화하는 대신 ELBO-term을 최대화하는 $\\phi$를 찾는 것이 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) **Reparameterization Trick** - ELBO-term을 극대화하는 학습을 할 때 Backpropagation을 가능하게 하기 위해\n",
    "* feed forward과정 내에 있는 $q(z|x)$분포로부터의 z를 sampling 하는것은 미분이 가능한 연산이 아니므로 BP 불가\n",
    "* 따라서 $ z = \\mu + logVar $ (non-deterministic하므로)가 아닌 $ z = \\mu + \\epsilon*(logVar) $ 로 변형 (eps: $N(0,1)$로 부터의 random sampling)\n",
    "* ELBO-term $= E_{q(z|x)}[log(p(x|z))] - KL(q_{\\phi}(z|x_i)||p(z))$ 에서 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) **Maximum Likelihood Estimation** - Decoder를 통해 잠재변수 z로부터 X와 근사한 분포를 추정(Reconstruct)하고 Encoder를 통해 X로부터 추출한 z가 사전분포 p(z)와 근사하도록 추정(Regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Reconstruction Error**(ELBO의 첫번째 term): $g_\\theta(z)$ 와 데이터 $X$의 분포를 최대로 유사하는 방향으로 학습하여 $ E_{q(z|x)}[log(p(x|z))]$ 를 최대화\n",
    "    * 방법1: ** $g_\\theta(z)$의 결과를 Bernnoulli Distribution 으로 가정**하여 $p_\\theta(x_i|z^i)$를 도출하고, 수식($log(p_\\theta(x_i|z^i)$)을 정리하면 $p_{i,j}$와 $X_{i,j}$의 **Cross Entropy 형태**\n",
    "    * 방법2: ** $g_\\theta(z)$의 결과를 Gaussian Distribution 으로 가정**하여 $\\mu, \\sigma$를 도출하고, 수식($log(p_\\theta(x_i|z^i)$)을 정리하면 **$\\mu_{i,j}$와 $X_{i,j}$의 MSE 형태**\n",
    "* **Regularization Error**(ELBO의 두번째 term): $q_{\\phi}(z|x_i)$를 \"아는 사전 분포\" $z$~$N(0,1)$와 유사한 방향으로 학습하여 $KL(q_{\\phi}(z|x_i)||p(z))$ 를 최소화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../shared/VAE_loss.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../shared/VAE_loss-all.png\" alt=\"Drawing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. MNIST 를 통한 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### (0) Define Hyper-parameters / Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Device Configuration for Where the Tensors Be Operated\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define OS Configuration\n",
    "sample_dir = './results'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "# Hyper-parameters\n",
    "image_size = 784\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "\n",
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision # To Download MNIST Datasets from Torch \n",
    "import torchvision.transforms as transforms # To Transform MNIST \"Images\" to \"Tensor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(root='./datasets',\n",
    "                                        train=True,\n",
    "                                        transform=transforms.ToTensor(),\n",
    "                                        download=True)\n",
    "\n",
    "# Doesn't Need Test Data (Going to be Sampled from z~N(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "# Doesn't Need Test Loader As Well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28]) : [Batch, Channel, Height, Width] Respectively\n"
     ]
    }
   ],
   "source": [
    "# cf) check how data_loader works\n",
    "image, label = next(iter(train_loader))\n",
    "print(image.size(), \": [Batch, Channel, Height, Width] Respectively\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=h_dim, z_dim=z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim) # from 784 Nodes(28x28 MNIST Image) to 400 Nodes (h_dim) \n",
    "        self.fc2 = nn.Linear(h_dim, z_dim) # from 400 Nodes (h_dim) to 20 Nodes (Dims of mean of z)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim) # from 400 Nodes (h_dim) to 20 Nodes (Dims of std of z)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim) # from 20 Nodes (reparameterized z=mean+eps*std) to 400 Nodes (h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size) # from 400 Nodes (h_dim) to 784 Nodes (Reconstructed 28x28 Image)\n",
    "        \n",
    "    # Encoder: Encode Image to Latent Vector z\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    # Reparameterize z=mean+std to z=mean+esp*std\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    # Decoder: Decode Reparameterized Latent Vector z to Reconstructed Image\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "    \n",
    "    # Feed Forward the Process and Outputs Estimated (Mean, Std, Reconstructed_Image) at the same time\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var\n",
    "\n",
    "model = VAE().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Set Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Total Loss is going to be defined in Training Part as it is a combination of Reconstruction Loss and Regularization Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load 'save_image' Function\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/usr/local/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/20], Step [50/469], Reconst Loss: 27043.2285, KL Div: 689.4911\n",
      "Epoch[1/20], Step [100/469], Reconst Loss: 21034.1328, KL Div: 1415.5076\n",
      "Epoch[1/20], Step [150/469], Reconst Loss: 19505.9648, KL Div: 1832.9268\n",
      "Epoch[1/20], Step [200/469], Reconst Loss: 16867.9688, KL Div: 2097.4224\n",
      "Epoch[1/20], Step [250/469], Reconst Loss: 16869.5898, KL Div: 2308.5818\n",
      "Epoch[1/20], Step [300/469], Reconst Loss: 16147.5137, KL Div: 2325.8838\n",
      "Epoch[1/20], Step [350/469], Reconst Loss: 15486.3750, KL Div: 2537.8840\n",
      "Epoch[1/20], Step [400/469], Reconst Loss: 14367.6504, KL Div: 2451.7480\n",
      "Epoch[1/20], Step [450/469], Reconst Loss: 13675.8486, KL Div: 2696.8506\n",
      "Epoch[2/20], Step [50/469], Reconst Loss: 12412.6924, KL Div: 2756.2368\n",
      "Epoch[2/20], Step [100/469], Reconst Loss: 12826.1221, KL Div: 2783.3357\n",
      "Epoch[2/20], Step [150/469], Reconst Loss: 12700.5537, KL Div: 2839.3696\n",
      "Epoch[2/20], Step [200/469], Reconst Loss: 12788.1787, KL Div: 2835.9673\n",
      "Epoch[2/20], Step [250/469], Reconst Loss: 11997.3789, KL Div: 2911.7800\n",
      "Epoch[2/20], Step [300/469], Reconst Loss: 12609.7695, KL Div: 2901.7124\n",
      "Epoch[2/20], Step [350/469], Reconst Loss: 12539.4023, KL Div: 2974.3823\n",
      "Epoch[2/20], Step [400/469], Reconst Loss: 11541.1162, KL Div: 3027.8193\n",
      "Epoch[2/20], Step [450/469], Reconst Loss: 12159.7988, KL Div: 3024.1731\n",
      "Epoch[3/20], Step [50/469], Reconst Loss: 11761.4961, KL Div: 3072.7522\n",
      "Epoch[3/20], Step [100/469], Reconst Loss: 11492.3447, KL Div: 3027.9111\n",
      "Epoch[3/20], Step [150/469], Reconst Loss: 11457.6387, KL Div: 3001.8984\n",
      "Epoch[3/20], Step [200/469], Reconst Loss: 11885.8047, KL Div: 3058.1296\n",
      "Epoch[3/20], Step [250/469], Reconst Loss: 11203.6035, KL Div: 3133.2800\n",
      "Epoch[3/20], Step [300/469], Reconst Loss: 11384.7822, KL Div: 3258.8694\n",
      "Epoch[3/20], Step [350/469], Reconst Loss: 11453.5127, KL Div: 3186.2632\n",
      "Epoch[3/20], Step [400/469], Reconst Loss: 11454.8975, KL Div: 3111.2583\n",
      "Epoch[3/20], Step [450/469], Reconst Loss: 12158.8291, KL Div: 3300.6687\n",
      "Epoch[4/20], Step [50/469], Reconst Loss: 11513.1797, KL Div: 3162.2522\n",
      "Epoch[4/20], Step [100/469], Reconst Loss: 11220.7754, KL Div: 3149.1128\n",
      "Epoch[4/20], Step [150/469], Reconst Loss: 11104.3213, KL Div: 3219.5171\n",
      "Epoch[4/20], Step [200/469], Reconst Loss: 10920.9111, KL Div: 3253.3730\n",
      "Epoch[4/20], Step [250/469], Reconst Loss: 11495.4473, KL Div: 3204.6145\n",
      "Epoch[4/20], Step [300/469], Reconst Loss: 10495.4199, KL Div: 3106.3708\n",
      "Epoch[4/20], Step [350/469], Reconst Loss: 10900.8643, KL Div: 3190.6824\n",
      "Epoch[4/20], Step [400/469], Reconst Loss: 11461.6641, KL Div: 3120.4436\n",
      "Epoch[4/20], Step [450/469], Reconst Loss: 11241.9746, KL Div: 3258.9749\n",
      "Epoch[5/20], Step [50/469], Reconst Loss: 10692.2803, KL Div: 3207.0398\n",
      "Epoch[5/20], Step [100/469], Reconst Loss: 10985.2969, KL Div: 3232.9849\n",
      "Epoch[5/20], Step [150/469], Reconst Loss: 11465.1074, KL Div: 3197.3140\n",
      "Epoch[5/20], Step [200/469], Reconst Loss: 11172.5938, KL Div: 3185.5200\n",
      "Epoch[5/20], Step [250/469], Reconst Loss: 10784.8105, KL Div: 3198.6633\n",
      "Epoch[5/20], Step [300/469], Reconst Loss: 11154.0732, KL Div: 3159.8921\n",
      "Epoch[5/20], Step [350/469], Reconst Loss: 10748.0332, KL Div: 3080.5410\n",
      "Epoch[5/20], Step [400/469], Reconst Loss: 10654.7998, KL Div: 3268.0037\n",
      "Epoch[5/20], Step [450/469], Reconst Loss: 10820.8740, KL Div: 3267.0715\n",
      "Epoch[6/20], Step [50/469], Reconst Loss: 10834.2656, KL Div: 3147.9399\n",
      "Epoch[6/20], Step [100/469], Reconst Loss: 10497.7012, KL Div: 3065.9312\n",
      "Epoch[6/20], Step [150/469], Reconst Loss: 11072.7285, KL Div: 3292.8911\n",
      "Epoch[6/20], Step [200/469], Reconst Loss: 10561.8389, KL Div: 3141.1548\n",
      "Epoch[6/20], Step [250/469], Reconst Loss: 10430.0732, KL Div: 3157.2124\n",
      "Epoch[6/20], Step [300/469], Reconst Loss: 10749.5742, KL Div: 3234.5903\n",
      "Epoch[6/20], Step [350/469], Reconst Loss: 11285.3574, KL Div: 3170.0876\n",
      "Epoch[6/20], Step [400/469], Reconst Loss: 10584.8711, KL Div: 3197.6172\n",
      "Epoch[6/20], Step [450/469], Reconst Loss: 10934.3896, KL Div: 3210.8596\n",
      "Epoch[7/20], Step [50/469], Reconst Loss: 10720.4307, KL Div: 3224.7344\n",
      "Epoch[7/20], Step [100/469], Reconst Loss: 11012.5742, KL Div: 3351.0796\n",
      "Epoch[7/20], Step [150/469], Reconst Loss: 10761.2559, KL Div: 3150.0400\n",
      "Epoch[7/20], Step [200/469], Reconst Loss: 10628.1504, KL Div: 3186.4871\n",
      "Epoch[7/20], Step [250/469], Reconst Loss: 10220.8760, KL Div: 3083.7930\n",
      "Epoch[7/20], Step [300/469], Reconst Loss: 10641.2100, KL Div: 3256.3586\n",
      "Epoch[7/20], Step [350/469], Reconst Loss: 10130.6836, KL Div: 3179.3245\n",
      "Epoch[7/20], Step [400/469], Reconst Loss: 10450.4707, KL Div: 3264.8813\n",
      "Epoch[7/20], Step [450/469], Reconst Loss: 10174.9629, KL Div: 3194.8215\n",
      "Epoch[8/20], Step [50/469], Reconst Loss: 10476.0547, KL Div: 3163.6040\n",
      "Epoch[8/20], Step [100/469], Reconst Loss: 10701.0283, KL Div: 3253.9326\n",
      "Epoch[8/20], Step [150/469], Reconst Loss: 10179.5840, KL Div: 3230.5073\n",
      "Epoch[8/20], Step [200/469], Reconst Loss: 10502.7314, KL Div: 3268.5652\n",
      "Epoch[8/20], Step [250/469], Reconst Loss: 10437.4141, KL Div: 3214.7979\n",
      "Epoch[8/20], Step [300/469], Reconst Loss: 10501.8154, KL Div: 3191.3079\n",
      "Epoch[8/20], Step [350/469], Reconst Loss: 10370.8086, KL Div: 3236.5347\n",
      "Epoch[8/20], Step [400/469], Reconst Loss: 10235.1367, KL Div: 3239.8362\n",
      "Epoch[8/20], Step [450/469], Reconst Loss: 9780.4541, KL Div: 3177.4070\n",
      "Epoch[9/20], Step [50/469], Reconst Loss: 10332.4971, KL Div: 3169.4932\n",
      "Epoch[9/20], Step [100/469], Reconst Loss: 10576.9072, KL Div: 3065.6426\n",
      "Epoch[9/20], Step [150/469], Reconst Loss: 10708.6680, KL Div: 3255.8379\n",
      "Epoch[9/20], Step [200/469], Reconst Loss: 10237.5654, KL Div: 3236.8640\n",
      "Epoch[9/20], Step [250/469], Reconst Loss: 10252.8730, KL Div: 3180.1709\n",
      "Epoch[9/20], Step [300/469], Reconst Loss: 10315.8604, KL Div: 3214.6855\n",
      "Epoch[9/20], Step [350/469], Reconst Loss: 10513.0293, KL Div: 3303.0056\n",
      "Epoch[9/20], Step [400/469], Reconst Loss: 10322.8135, KL Div: 3272.2998\n",
      "Epoch[9/20], Step [450/469], Reconst Loss: 10544.5469, KL Div: 3321.1777\n",
      "Epoch[10/20], Step [50/469], Reconst Loss: 10035.5312, KL Div: 3271.4309\n",
      "Epoch[10/20], Step [100/469], Reconst Loss: 10533.7959, KL Div: 3134.9517\n",
      "Epoch[10/20], Step [150/469], Reconst Loss: 10872.1855, KL Div: 3284.3962\n",
      "Epoch[10/20], Step [200/469], Reconst Loss: 10714.2969, KL Div: 3221.6819\n",
      "Epoch[10/20], Step [250/469], Reconst Loss: 10490.1445, KL Div: 3180.2334\n",
      "Epoch[10/20], Step [300/469], Reconst Loss: 10102.4092, KL Div: 3211.2422\n",
      "Epoch[10/20], Step [350/469], Reconst Loss: 10535.3691, KL Div: 3195.6492\n",
      "Epoch[10/20], Step [400/469], Reconst Loss: 10067.3350, KL Div: 3236.0525\n",
      "Epoch[10/20], Step [450/469], Reconst Loss: 10149.6377, KL Div: 3214.7642\n",
      "Epoch[11/20], Step [50/469], Reconst Loss: 10250.6279, KL Div: 3231.4783\n",
      "Epoch[11/20], Step [100/469], Reconst Loss: 10549.4199, KL Div: 3264.3032\n",
      "Epoch[11/20], Step [150/469], Reconst Loss: 10293.9805, KL Div: 3167.5022\n",
      "Epoch[11/20], Step [200/469], Reconst Loss: 10161.9463, KL Div: 3161.8899\n",
      "Epoch[11/20], Step [250/469], Reconst Loss: 10070.4248, KL Div: 3274.8079\n",
      "Epoch[11/20], Step [300/469], Reconst Loss: 11066.6426, KL Div: 3282.8252\n",
      "Epoch[11/20], Step [350/469], Reconst Loss: 10194.3564, KL Div: 3241.4456\n",
      "Epoch[11/20], Step [400/469], Reconst Loss: 10018.3018, KL Div: 3203.0518\n",
      "Epoch[11/20], Step [450/469], Reconst Loss: 10223.4463, KL Div: 3220.4226\n",
      "Epoch[12/20], Step [50/469], Reconst Loss: 10493.5479, KL Div: 3273.1675\n",
      "Epoch[12/20], Step [100/469], Reconst Loss: 10356.4248, KL Div: 3254.6514\n",
      "Epoch[12/20], Step [150/469], Reconst Loss: 10616.6543, KL Div: 3295.2590\n",
      "Epoch[12/20], Step [200/469], Reconst Loss: 10118.4775, KL Div: 3220.6523\n",
      "Epoch[12/20], Step [250/469], Reconst Loss: 10054.0430, KL Div: 3219.6792\n",
      "Epoch[12/20], Step [300/469], Reconst Loss: 9944.7070, KL Div: 3066.9761\n",
      "Epoch[12/20], Step [350/469], Reconst Loss: 10285.9463, KL Div: 3281.3086\n",
      "Epoch[12/20], Step [400/469], Reconst Loss: 10467.7148, KL Div: 3225.4377\n",
      "Epoch[12/20], Step [450/469], Reconst Loss: 9901.8691, KL Div: 3228.4690\n",
      "Epoch[13/20], Step [50/469], Reconst Loss: 10666.4199, KL Div: 3322.4160\n",
      "Epoch[13/20], Step [100/469], Reconst Loss: 10568.4785, KL Div: 3252.6292\n",
      "Epoch[13/20], Step [150/469], Reconst Loss: 9969.4170, KL Div: 3211.6003\n",
      "Epoch[13/20], Step [200/469], Reconst Loss: 9821.8711, KL Div: 3241.0237\n",
      "Epoch[13/20], Step [250/469], Reconst Loss: 10133.8408, KL Div: 3253.6880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[13/20], Step [300/469], Reconst Loss: 10113.7803, KL Div: 3165.8167\n",
      "Epoch[13/20], Step [350/469], Reconst Loss: 10065.7686, KL Div: 3288.4292\n",
      "Epoch[13/20], Step [400/469], Reconst Loss: 10125.1221, KL Div: 3114.6873\n",
      "Epoch[13/20], Step [450/469], Reconst Loss: 10762.6406, KL Div: 3220.4175\n",
      "Epoch[14/20], Step [50/469], Reconst Loss: 10384.0479, KL Div: 3305.6655\n",
      "Epoch[14/20], Step [100/469], Reconst Loss: 10105.0029, KL Div: 3344.3110\n",
      "Epoch[14/20], Step [150/469], Reconst Loss: 10255.1602, KL Div: 3266.5461\n",
      "Epoch[14/20], Step [200/469], Reconst Loss: 10026.7686, KL Div: 3295.8701\n",
      "Epoch[14/20], Step [250/469], Reconst Loss: 10476.5791, KL Div: 3181.1997\n",
      "Epoch[14/20], Step [300/469], Reconst Loss: 10312.2764, KL Div: 3229.7793\n",
      "Epoch[14/20], Step [350/469], Reconst Loss: 10324.7256, KL Div: 3220.8438\n",
      "Epoch[14/20], Step [400/469], Reconst Loss: 10080.6201, KL Div: 3233.8140\n",
      "Epoch[14/20], Step [450/469], Reconst Loss: 10330.5430, KL Div: 3276.0830\n",
      "Epoch[15/20], Step [50/469], Reconst Loss: 9886.5557, KL Div: 3154.5161\n",
      "Epoch[15/20], Step [100/469], Reconst Loss: 10287.3984, KL Div: 3255.3184\n",
      "Epoch[15/20], Step [150/469], Reconst Loss: 10143.0527, KL Div: 3206.5493\n",
      "Epoch[15/20], Step [200/469], Reconst Loss: 10164.4580, KL Div: 3273.5515\n",
      "Epoch[15/20], Step [250/469], Reconst Loss: 9967.1367, KL Div: 3140.8545\n",
      "Epoch[15/20], Step [300/469], Reconst Loss: 10216.1514, KL Div: 3210.2166\n",
      "Epoch[15/20], Step [350/469], Reconst Loss: 9845.0508, KL Div: 3202.5984\n",
      "Epoch[15/20], Step [400/469], Reconst Loss: 10343.2900, KL Div: 3255.8955\n",
      "Epoch[15/20], Step [450/469], Reconst Loss: 10369.9453, KL Div: 3286.1694\n",
      "Epoch[16/20], Step [50/469], Reconst Loss: 10009.5840, KL Div: 3240.0613\n",
      "Epoch[16/20], Step [100/469], Reconst Loss: 10368.6777, KL Div: 3237.0544\n",
      "Epoch[16/20], Step [150/469], Reconst Loss: 10093.1475, KL Div: 3202.5615\n",
      "Epoch[16/20], Step [200/469], Reconst Loss: 10316.2549, KL Div: 3200.7344\n",
      "Epoch[16/20], Step [250/469], Reconst Loss: 10421.0225, KL Div: 3261.0327\n",
      "Epoch[16/20], Step [300/469], Reconst Loss: 9300.7451, KL Div: 3187.5327\n",
      "Epoch[16/20], Step [350/469], Reconst Loss: 9403.5713, KL Div: 3139.0063\n",
      "Epoch[16/20], Step [400/469], Reconst Loss: 10567.3193, KL Div: 3258.2278\n",
      "Epoch[16/20], Step [450/469], Reconst Loss: 10005.7822, KL Div: 3288.5938\n",
      "Epoch[17/20], Step [50/469], Reconst Loss: 10161.4697, KL Div: 3336.2251\n",
      "Epoch[17/20], Step [100/469], Reconst Loss: 9868.3525, KL Div: 3273.9297\n",
      "Epoch[17/20], Step [150/469], Reconst Loss: 10169.2217, KL Div: 3189.2947\n",
      "Epoch[17/20], Step [200/469], Reconst Loss: 10161.7188, KL Div: 3139.9995\n",
      "Epoch[17/20], Step [250/469], Reconst Loss: 10173.1377, KL Div: 3278.9021\n",
      "Epoch[17/20], Step [300/469], Reconst Loss: 10150.1348, KL Div: 3260.1035\n",
      "Epoch[17/20], Step [350/469], Reconst Loss: 10342.2197, KL Div: 3287.3633\n",
      "Epoch[17/20], Step [400/469], Reconst Loss: 9699.0811, KL Div: 3214.7192\n",
      "Epoch[17/20], Step [450/469], Reconst Loss: 10104.2002, KL Div: 3234.5469\n",
      "Epoch[18/20], Step [50/469], Reconst Loss: 9942.0322, KL Div: 3346.3071\n",
      "Epoch[18/20], Step [100/469], Reconst Loss: 10113.1855, KL Div: 3241.8567\n",
      "Epoch[18/20], Step [150/469], Reconst Loss: 10653.7139, KL Div: 3434.7158\n",
      "Epoch[18/20], Step [200/469], Reconst Loss: 10080.6592, KL Div: 3276.2129\n",
      "Epoch[18/20], Step [250/469], Reconst Loss: 10161.5225, KL Div: 3238.4893\n",
      "Epoch[18/20], Step [300/469], Reconst Loss: 9974.0615, KL Div: 3195.7734\n",
      "Epoch[18/20], Step [350/469], Reconst Loss: 9880.6113, KL Div: 3330.8713\n",
      "Epoch[18/20], Step [400/469], Reconst Loss: 10084.1113, KL Div: 3233.7568\n",
      "Epoch[18/20], Step [450/469], Reconst Loss: 9931.9756, KL Div: 3213.1719\n",
      "Epoch[19/20], Step [50/469], Reconst Loss: 10243.9561, KL Div: 3215.2544\n",
      "Epoch[19/20], Step [100/469], Reconst Loss: 10071.5312, KL Div: 3208.4436\n",
      "Epoch[19/20], Step [150/469], Reconst Loss: 10186.1406, KL Div: 3433.6174\n",
      "Epoch[19/20], Step [200/469], Reconst Loss: 10015.5557, KL Div: 3346.2490\n",
      "Epoch[19/20], Step [250/469], Reconst Loss: 10358.1309, KL Div: 3311.5022\n",
      "Epoch[19/20], Step [300/469], Reconst Loss: 9851.3164, KL Div: 3198.9180\n",
      "Epoch[19/20], Step [350/469], Reconst Loss: 9664.0928, KL Div: 3084.6492\n",
      "Epoch[19/20], Step [400/469], Reconst Loss: 10194.1465, KL Div: 3335.2969\n",
      "Epoch[19/20], Step [450/469], Reconst Loss: 10741.6670, KL Div: 3250.7144\n",
      "Epoch[20/20], Step [50/469], Reconst Loss: 10123.9492, KL Div: 3306.9585\n",
      "Epoch[20/20], Step [100/469], Reconst Loss: 10113.7734, KL Div: 3270.0024\n",
      "Epoch[20/20], Step [150/469], Reconst Loss: 10010.1543, KL Div: 3336.0569\n",
      "Epoch[20/20], Step [200/469], Reconst Loss: 10249.7373, KL Div: 3180.1194\n",
      "Epoch[20/20], Step [250/469], Reconst Loss: 9831.5312, KL Div: 3299.4431\n",
      "Epoch[20/20], Step [300/469], Reconst Loss: 10287.3271, KL Div: 3239.2480\n",
      "Epoch[20/20], Step [350/469], Reconst Loss: 9472.8535, KL Div: 3172.9434\n",
      "Epoch[20/20], Step [400/469], Reconst Loss: 9910.8691, KL Div: 3248.7612\n",
      "Epoch[20/20], Step [450/469], Reconst Loss: 9575.1602, KL Div: 3281.6675\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(train_loader): # '_' as we don't need label of the input Image\n",
    "        # Feed Forward\n",
    "        x = x.to(device).view(-1, image_size) # Flatten 2D Image into 1D Nodes\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "        \n",
    "        # Compute the Total Loss\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False) # See the Description below\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        \n",
    "        # Get Loss, Compute Gradient, Update Parameters\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print Loss for Tracking Training\n",
    "        if (i+1) % 50 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \n",
    "                   .format(epoch+1, num_epochs, i+1, len(train_loader), reconst_loss.item(), kl_div.item()))\n",
    "            \n",
    "    # Save Model on Last epoch\n",
    "    if epoch+1 == num_epochs:\n",
    "        torch.save(model.state_dict(), './model.pth')\n",
    "    \n",
    "    # Save Generated Image and Reconstructed Image at every Epoch\n",
    "    with torch.no_grad():\n",
    "        # Save the sampled images\n",
    "        z = torch.randn(batch_size, z_dim).to(device) # Randomly Sample z\n",
    "        out = model.decode(z).view(-1, 1, 28, 28)\n",
    "        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "\n",
    "        # Save the reconstructed images\n",
    "        out, _, _ = model(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a href=\"https://pytorch.org/docs/stable/_modules/torch/nn/functional.html#binary_cross_entropy\" target=\"_blank\">cf) Pytorch for F.binaray_cross_entropy</a>\n",
    "size_average: default=True (Loss 를 element 크기로 평균) / False로 선언하면 Loss 는 각 element의 loss의 합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. 시각화를 통한 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 예제에서 선언한 20차원의 Multivarient Gaussian Distribution 으로 표현한 MNIST 데이터 분포"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../shared/VAE_MNIST_output.png\" alt=\"Drawing\" style=\"width: 800px;\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. MNIST 분포 추정 과정 [[link](https://github.com/gamchanr/TA-EE4178/blob/master/shared/VAE_MNIST_simulation.gif)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../shared/VAE_MNIST_simulation.gif\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [오토인코더의 모든 것](https://www.youtube.com/watch?v=o_peo6U7IRM)<br>\n",
    "* [Jeremy Jordan VAE](https://www.jeremyjordan.me/variational-autoencoders/)<br>\n",
    "* [Joseph Rocca VAE](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73) <br>\n",
    "* [Taeu Kim VAE paper review](https://taeu.github.io/paper/deeplearning-paper-vae/)\n",
    "* [Ratsgo VAE](https://ratsgo.github.io/generative%20model/2018/01/27/VAE/)\n",
    "* [Multivariate Gaussian Distribution](https://www.sallys.space/blog/2018/03/20/multivariate-gaussian/)\n",
    "* [BCE](https://curt-park.github.io/2018-09-19/loss-cross-entropy/)\n",
    "* [Pytorch Official VAE Tutorial](https://github.com/pytorch/examples/blob/master/vae/main.py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
