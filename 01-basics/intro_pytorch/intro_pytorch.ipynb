{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 개론 (+Google Colab 사용법)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf. Google Colab: [[링크](https://colab.research.google.com/notebooks/welcome.ipynb)] [[사용법](https://drive.google.com/file/d/11B7cjkW0KVMZv-yqxHDhg0TUE3CESYSx/view)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Basic Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 자료형과 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 숫자형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1.2\n",
      "11.2 8.8 12.0 8.333333333333334\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 1.2\n",
    "print(a, b)\n",
    "print(a+b, a-b, a*b, a/b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문자열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life is too short, Python is fast\n"
     ]
    }
   ],
   "source": [
    "quote = \"Life is too short,\"\n",
    "print(quote, \"Python is fast\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 리스트 / 튜플"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 'Life', ['a', 'b', 'c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(a[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c']\n"
     ]
    }
   ],
   "source": [
    "print(a[-1]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    }
   ],
   "source": [
    "print(a[-1][1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(a[0:2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 'Life', ['a', 'b', 'c'], 'short']\n"
     ]
    }
   ],
   "source": [
    "a.append('short') \n",
    "a.insert(2, 3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 튜플: 리스트와 비슷하지만 요소값 생성, 삭제, 수정이 불가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 딕셔너리 / 집합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'key': 'value', '류현진': '야구', '손흥민': '축구'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "야구\n"
     ]
    }
   ],
   "source": [
    "print(dic['류현진']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['key', '류현진', '손흥민'])\n"
     ]
    }
   ],
   "source": [
    "print(dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['value', '야구', '축구'])\n"
     ]
    }
   ],
   "source": [
    "print(dic.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'value', '류현진': '야구', '손흥민': '축구', 'new key': 'new value'}\n"
     ]
    }
   ],
   "source": [
    "dic['new key'] = 'new value' \n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 제어문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if 문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 is even number\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "if a[1]%2==0:\n",
    "    print(\"{} is even number\".format(a[1]))\n",
    "elif a[1]%2==1:\n",
    "    print(\"{} is odd number\".format(a[1]))\n",
    "else:\n",
    "    print(\"Impossible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for 문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### while 문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "while True:\n",
    "    if a == 3:\n",
    "        break\n",
    "    print(a) \n",
    "    a +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 함수 / 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "def square_sum(a, b):\n",
    "    squared_a = a**2\n",
    "    squared_b = b**2\n",
    "    return squared_a + squared_b\n",
    "\n",
    "c = square_sum(3, 4)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 클래스 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example for initializing a Class\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "class Calculator():\n",
    "    def __init__(self):\n",
    "        self.description = \"Example for initializing a Class\"\n",
    "        self.result = 0\n",
    "\n",
    "    def add(self, numb1, numb2):\n",
    "        if type(numb1) == int and type(numb2) == int:\n",
    "            result = numb1 + numb2\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception\n",
    "\n",
    "cal = Calculator()\n",
    "print(cal.description)\n",
    "print(cal.add(10, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4 Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([1,2,3])\n",
    "print(a, type(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Tensors / Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors / Numpy / Python List\n",
    "* Python List: 행렬연산을 위해 for 문을 사용  \n",
    "* Numpy: 조건에 따라 차원이 다른 배열간의 연산을 가능하게 하는 Broadcasting을 사용하여 연산가능  \n",
    "* Tensor: pytorch의 자료형으로 numpy배열과 비슷하나, GPU에서의 연산이 가능하고, Pytorch의 Autograd(자동미분) 연산 가능 [[참고](https://blog.naver.com/PostView.nhn?blogId=qbxlvnf11&logNo=221558405051)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 초기화 되지 않은 행렬 생성\n",
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2293, 0.8191, 0.6608],\n",
      "        [0.4741, 0.3224, 0.7111],\n",
      "        [0.1115, 0.9771, 0.6515],\n",
      "        [0.8860, 0.3049, 0.8640],\n",
      "        [0.2466, 0.6238, 0.8027]])\n"
     ]
    }
   ],
   "source": [
    "# 0~1 사이에서 랜덤으로 초기화된 행렬 생성\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0713,  0.3136,  1.8314],\n",
      "        [-0.9365,  0.4813, -0.3294],\n",
      "        [ 0.8300,  0.1401,  0.8281],\n",
      "        [-0.8945,  0.7839, -0.3687],\n",
      "        [ 0.0426,  0.9969,  0.6268]])\n"
     ]
    }
   ],
   "source": [
    "# Standard Normal Distribution 에서 랜덤으로 초기화된 행렬 생성\n",
    "x = torch.randn(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2000, 2.4000])\n"
     ]
    }
   ],
   "source": [
    "# 값 지정하여 행렬 생성\n",
    "x = torch.tensor([1.2, 2.4])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5134,  1.4043, -1.1669],\n",
      "        [-1.1221,  1.1167, -0.4580],\n",
      "        [ 0.6407, -1.4621,  0.0329],\n",
      "        [ 1.4027,  0.4858,  0.2261],\n",
      "        [ 0.4003,  0.2429, -0.4176]]) \n",
      " tensor([[ 1.9055,  0.5555,  0.3105],\n",
      "        [-1.0860, -0.1137,  1.4385],\n",
      "        [-0.5781,  0.7907, -0.8432],\n",
      "        [-0.4439, -0.5614,  0.8820],\n",
      "        [-0.9303, -0.0091,  0.3918]]) \n",
      " tensor([[ 1.3921,  1.9598, -0.8564],\n",
      "        [-2.2081,  1.0030,  0.9805],\n",
      "        [ 0.0625, -0.6713, -0.8103],\n",
      "        [ 0.9588, -0.0756,  1.1081],\n",
      "        [-0.5300,  0.2338, -0.0258]])\n"
     ]
    }
   ],
   "source": [
    "# 덧셈\n",
    "x = torch.randn(5, 3)\n",
    "y = torch.randn(5, 3)\n",
    "print(x, '\\n', y, '\\n', x+y) # x+y = torch.add(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor 사이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "# Size 확인\n",
    "x = torch.randn(4, 4)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# Resize - view\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.size(), z.size())\n",
    "\n",
    "# Resize - reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor, Numpy 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.]) <class 'torch.Tensor'>\n",
      "[1. 1. 1. 1. 1.] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Tensor to Numpy\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a, type(a))\n",
    "print(b, type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.] <class 'numpy.ndarray'>\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Numpy to Tensor\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a, type(a))\n",
    "print(b, type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 연산을 위한 CUDA Tensor\n",
    "a = torch.ones(5)\n",
    "# b = a.to(device=\"cudo:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Autograd  \n",
    "requires_grad 를 true로 세팅하면, 텐서의 모든 연산에 대한 추적 가능  \n",
    "이를 통해 forward propagation 후 .backward() 호출 시 모든 gradient를 자동으로 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27.,  48.],\n",
      "        [ 75., 108.]], grad_fn=<MulBackward0>)\n",
      "tensor(64.5000, grad_fn=<MeanBackward0>)\n",
      "tensor([[4.5000, 6.0000],\n",
      "        [7.5000, 9.0000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1., 2.], [3., 4.]], requires_grad=True) # default requires_grad for input data: False (whereas default requires_grad for each layer is True)\n",
    "y = (x+2)**2*3\n",
    "print(y)\n",
    "\n",
    "out = y.mean()\n",
    "print(out)\n",
    "\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\because {dout\\over dx_i} = {dout \\over dy} * {dy \\over dx_i} = {1 \\over 4}*6(x_i+2) = {3\\over2}(x_i+2) \\hspace{1cm}$\n",
    "as ${dout \\over dy} = {1 \\over 4}, {dy \\over dx_i} = 6(x_i+2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 PyTorch Project 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision # to download 'CIFAR10' dataset\n",
    "import torchvision.transforms as transforms # to manipulate input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root='./datasets', \n",
    "                                          train=True, \n",
    "                                          transform=transforms.ToTensor(), \n",
    "                                          download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 torch.Size([3, 32, 32]) 6\n"
     ]
    }
   ],
   "source": [
    "# cf) check for the data\n",
    "image, label = train_data[0]\n",
    "print(len(train_data), image.size(), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define Dataloader\n",
    "define dataloader (when iters loop, dataloader loads data from queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=train_data, \n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n",
      "torch.Size([64, 3, 32, 32]) tensor([8, 0, 6, 1, 0, 4, 1, 3, 7, 0, 9, 0, 1, 0, 4, 5, 6, 9, 4, 8, 5, 3, 2, 5,\n",
      "        6, 9, 4, 0, 0, 9, 0, 2, 4, 6, 9, 9, 6, 2, 2, 3, 9, 3, 3, 2, 0, 1, 1, 5,\n",
      "        2, 4, 9, 6, 1, 4, 2, 8, 7, 9, 0, 3, 6, 5, 5, 4])\n",
      "torch.Size([64, 3, 32, 32]) tensor([0, 2, 9, 5, 0, 6, 0, 8, 4, 9, 7, 6, 8, 9, 1, 6, 9, 3, 0, 5, 4, 4, 5, 3,\n",
      "        3, 5, 3, 7, 6, 4, 3, 2, 1, 7, 7, 1, 5, 5, 1, 8, 2, 1, 7, 6, 6, 0, 1, 3,\n",
      "        9, 0, 0, 8, 9, 1, 3, 3, 9, 8, 8, 8, 7, 3, 1, 1])\n",
      "torch.Size([64, 3, 32, 32]) tensor([5, 8, 4, 1, 4, 4, 1, 8, 9, 5, 4, 0, 6, 6, 2, 4, 4, 7, 5, 6, 8, 5, 7, 6,\n",
      "        6, 3, 2, 1, 4, 0, 7, 5, 9, 0, 6, 8, 3, 5, 2, 0, 4, 2, 1, 5, 6, 9, 3, 3,\n",
      "        4, 8, 4, 3, 8, 1, 0, 7, 3, 6, 5, 9, 3, 5, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "# cf) check how data_loader works\n",
    "print(len(data_loader))\n",
    "for idx, (images, labels) in enumerate(data_loader):\n",
    "    if idx == 3:\n",
    "        break\n",
    "    print(images.size(), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc = nn.Linear(6*14*14, 10) # 10 final nodes as CIFAR10 dataset has 10 classes\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=1176, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# cf) check which layers constitute Network\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10]) \n",
      " tensor([ 0.4089, -0.2182, -0.4466, -0.0088, -0.1428,  0.5790,  0.1412, -0.4844,\n",
      "        -0.3540,  0.3355], grad_fn=<SelectBackward>) \n",
      " 5\n"
     ]
    }
   ],
   "source": [
    "# cf) check how data passes through the Network\n",
    "data_iter = iter(data_loader)\n",
    "images, labels = data_iter.next() # only get one mini-batch\n",
    "outputs = model(images)\n",
    "print(outputs.size(), '\\n', outputs[0], '\\n', outputs[0].tolist().index(max(outputs[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Set Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/782], Loss: 2.5608\n",
      "Epoch [1/1], Step [51/782], Loss: 2.1926\n",
      "Epoch [1/1], Step [101/782], Loss: 2.2277\n",
      "Epoch [1/1], Step [151/782], Loss: 2.1032\n",
      "Epoch [1/1], Step [201/782], Loss: 2.1232\n",
      "Epoch [1/1], Step [251/782], Loss: 2.0301\n",
      "Epoch [1/1], Step [301/782], Loss: 2.0593\n",
      "Epoch [1/1], Step [351/782], Loss: 2.0538\n",
      "Epoch [1/1], Step [401/782], Loss: 2.0368\n",
      "Epoch [1/1], Step [451/782], Loss: 2.0212\n",
      "Epoch [1/1], Step [501/782], Loss: 1.9060\n",
      "Epoch [1/1], Step [551/782], Loss: 1.8930\n",
      "Epoch [1/1], Step [601/782], Loss: 1.9998\n",
      "Epoch [1/1], Step [651/782], Loss: 2.0483\n",
      "Epoch [1/1], Step [701/782], Loss: 1.9342\n",
      "Epoch [1/1], Step [751/782], Loss: 1.9650\n",
      "Epoch [1/1], Step [782/782], Loss: 1.7977\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        # Forward Propagate\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Get Loss, Compute Gradient, Update Parameters\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%50 == 0 or i+1==len(data_loader):\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, i+1, len(data_loader), loss.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Save & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mdatasets\u001b[m\u001b[m            intro_pytorch.ipynb model.ckpt\r\n"
     ]
    }
   ],
   "source": [
    "# cf) check the saved model\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
